import streamlit as st
import requests

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ."}
    ]

# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
st.title("üí¨ –û–Ω–ª–∞–π–Ω GPT-–±–æ—Ç –±–µ–∑ —Ç–æ–∫–µ–Ω–æ–≤")

for msg in st.session_state.messages[1:]:  # –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º system
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
prompt = st.chat_input("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å...")

# === –§–£–ù–ö–¶–ò–Ø –ó–ê–ü–†–û–°–ê –ö –û–ù–õ–ê–ô–ù LLM ===
def ask_online_llm(messages):
    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Content-Type": "application/json",
        },
        json={
            "model": "mistralai/mistral-7b-instruct",
            "messages": messages,
            "max_tokens": 300,
        },
    )

    if response.status_code != 200:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {response.status_code}"

    return response.json()["choices"][0]["message"]["content"]

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è ===
if prompt:
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("–ü–∏—à—É –æ—Ç–≤–µ—Ç..."):
            reply = ask_online_llm(st.session_state.messages)
            st.markdown(reply)

    st.session_state.messages.append({"role": "assistant", "content": reply})
